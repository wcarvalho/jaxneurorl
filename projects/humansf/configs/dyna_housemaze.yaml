"ALG": 'qlearning'

# EXPERIMENT PARAMS
"NUM_SEEDS": 1
"SEED": 1

# logggin
"MAX_EPISODE_LOG_LEN": 40


# RUN PARAMS
"NUM_ENVS": 32
"EVAL_STEPS": 100
"EVAL_EPISODES": 100
"LEARNER_LOG_PERIOD": 500
"LEARNER_EXTRA_LOG_PERIOD": 5_000
"EVAL_LOG_PERIOD": 25
"EVAL_LOG_PERIOD_ACTOR": 0
"GRADIENT_LOG_PERIOD": 5_000

# NEURAL NET PARAMS
"AGENT_HIDDEN_DIM": 32
"NUM_EMBED_LAYERS": 0
"NUM_GRID_LAYERS": 1
"NUM_ENCODER_LAYERS": 2
"IMAGE_HIDDEN": 256
"ENCODER_INIT": 'word_init'
"AGENT_RNN_DIM": 256

# ALGO PARAMS
"BUFFER_SIZE": 50_000
"BUFFER_BATCH_SIZE": 32
"SAMPLE_LENGTH": 40
"LEARNING_STARTS": 10_000
"TRAINING_INTERVAL": 10

# DYNA PARAMS
"NUM_SIMULATIONS": 15
"SIMULATION_LENGTH": 5
"DYNA_COEFF": 0.1
"STOP_DYNA_GRAD": True
"TEMP_CONCENTRATION": .5
"TEMP_RATE": .5


"FIXED_EPSILON": 2 # range of epsilons
"TOTAL_TIMESTEPS": 1e8
"EPSILON_START": 1.0
"EPSILON_FINISH": 0.1
"EPSILON_ANNEAL_TIME": 5e5
"MAX_GRAD_NORM": 80
"TARGET_UPDATE_INTERVAL": 1_000
"LR": 0.001
"LR_LINEAR_DECAY": FALSE
"EPS_ADAM": 0.00001

"GAMMA": 0.99

hydra/output_subdir: null
hydra/hydra_logging: disabled
hydra/job_logging: disabled


defaults:
- _self_
- user: wilka.yaml
- debug: short.yaml
- env: housemaze.yaml
