"ALG": 'qlearning'

# EXPERIMENT PARAMS
"NUM_SEEDS": 1
"SEED": 1

# logggin
"MAX_EPISODE_LOG_LEN": 40


"NUM_EXTRA_REPLAY": 50_000
# RUN PARAMS
"NUM_ENVS": 32
"EVAL_STEPS": 100
"EVAL_EPISODES": 100
"LEARNER_LOG_PERIOD": 500
"LEARNER_EXTRA_LOG_PERIOD": 10_000
"EVAL_LOG_PERIOD": 50
"EVAL_LOG_PERIOD_ACTOR": 0
"GRADIENT_LOG_PERIOD": 0

# NEURAL NET PARAMS
"AGENT_HIDDEN_DIM": 32
"NUM_EMBED_LAYERS": 0
"NUM_GRID_LAYERS": 1
"NUM_ENCODER_LAYERS": 2
"GRID_HIDDEN": 256
"ENCODER_INIT": 'word_init'
"AGENT_RNN_DIM": 256

# ALGO PARAMS
"BUFFER_SIZE": 50_000
"TOTAL_BATCH_SIZE": 1280
"BUFFER_BATCH_SIZE": 32
"SAMPLE_LENGTH": null
"TOTAL_EXTRA_BATCH_SIZE": null
"EXTRA_BATCH_SIZE": 32
"EXTRA_SAMPLE_LENGTH": null
"LEARNING_STARTS": 10_000
"TRAINING_INTERVAL": 5

# DYNA PARAMS
"NUM_SIMULATIONS": 15
"SIMULATION_LENGTH": 5
"DYNA_COEFF": 0.1
"STOP_DYNA_GRAD": True
"TEMP_CONCENTRATION": .25
"TEMP_RATE": .5


"FIXED_EPSILON": 2 # range of epsilons
"TOTAL_TIMESTEPS": int(1e8)
"EPSILON_START": 1.0
"EPSILON_FINISH": 0.1
"EPSILON_ANNEAL_TIME": 5e5
"MAX_GRAD_NORM": 80
"TARGET_UPDATE_INTERVAL": 1_000
"LR": 0.001
"LR_LINEAR_DECAY": FALSE
"EPS_ADAM": 0.00001

"GAMMA": 0.99

hydra/output_subdir: null
hydra/hydra_logging: disabled
hydra/job_logging: disabled


defaults:
- _self_
- user: wilka.yaml
- debug: short.yaml
- rlenv: housemaze.yaml
